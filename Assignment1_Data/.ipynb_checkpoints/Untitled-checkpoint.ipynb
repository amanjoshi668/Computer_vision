{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Camera Calibration\n",
    "<div align=\"left\">\n",
    "- Aman Joshi\n",
    "- 2018201097\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T15:27:02.858848Z",
     "start_time": "2019-02-03T15:27:02.074249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from sympy import Matrix\n",
    "import random\n",
    "import cv2 as cv\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T15:27:02.864218Z",
     "start_time": "2019-02-03T15:27:02.860569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera class \n",
    "The class represent a camera that has some parameters like **K, R, P, t**. It also contain functions like :\n",
    "- get_camera_parameters: It will calculate camera parameters using DLT. \n",
    "- get_image_coordinates: It will map a 3-D real world point to 2-D image point.\n",
    "- RANSAC: It will calculate camera parameters using DLT.\n",
    "## DLT\n",
    "It is a Camera Calibration technique that require mapping of 3D real world coordinates to 2D image coordinates. The real world coordinates can be represented as\\begin{equation*}\n",
    "X = [x\\ y\\ z\\ w]\n",
    "\\end{equation*}\n",
    "while the image coordinates can be represented as \\begin{equation*}\n",
    "\\bar{x} = [u\\ v\\ w]\n",
    "\\end{equation*}\n",
    "the transformation from 3D points to 2D points can be done through a **3 X 3** matrix **P** .\n",
    "Thus combining above \n",
    "\\begin{equation}\\label{eq:}\n",
    "X = P\\bar{x}\n",
    "\\end{equation}\n",
    "\n",
    "Where P is the camera matrix and can be represented as\\begin{equation*}\n",
    "P = K[R|t] = KR|Kt\n",
    "\\end{equation*}\n",
    "Where __K__ is the intrinsic parameters of camera while **R** , **t** are rotational and transational matrices and vectors.\n",
    "\n",
    "However this can be further solved using\\begin{equation*}\n",
    "KR*(KR)^T = KK^T\n",
    "\\end{equation*}\n",
    "It can be solved to find K which then can be used to find R and t.\n",
    "## RANSAC\n",
    "Random sample consensus (RANSAC) is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates. Therefore, it also can be interpreted as an outlier detection method.\n",
    "I ve set number of iterations to be 100 and threshold to 200. Where 200 is the allowed euclidean distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-03T15:27:05.012158Z",
     "start_time": "2019-02-03T15:27:02.868029Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    def __init__(self):\n",
    "        self.P = None\n",
    "        self.K = self.R = self.C = None\n",
    "\n",
    "    def change_K(self, K):\n",
    "        self.K = np.array(K)\n",
    "        self.KR = np.dot(self.K, self.R)\n",
    "        self.Kt = np.dot(self.K, self.t)\n",
    "        #         display(self.K, self.R, self.t, self.KR, self.Kt)\n",
    "        self.P = np.concatenate((self.KR, self.Kt), axis=1)\n",
    "\n",
    "    def get_camera_parameters(self,\n",
    "                              real_world_coordinates,\n",
    "                              image_coordinates,\n",
    "                              change=True):\n",
    "        size = len(real_world_coordinates) * 2\n",
    "        A = np.empty(shape=(size, 12))\n",
    "        count = 0\n",
    "        for real_point, image_point in zip(real_world_coordinates,\n",
    "                                           image_coordinates):\n",
    "            #             print(real_point, image_point)\n",
    "            A[count] = np.array([\n",
    "                -real_point[0], -real_point[1], -real_point[2], -1, 0, 0, 0, 0,\n",
    "                real_point[0] * image_point[0], real_point[1] * image_point[0],\n",
    "                real_point[2] * image_point[0], image_point[0]\n",
    "            ])\n",
    "            A[count + 1] = np.array([\n",
    "                0, 0, 0, 0, -real_point[0], -real_point[1], -real_point[2], -1,\n",
    "                real_point[0] * image_point[1], real_point[1] * image_point[1],\n",
    "                real_point[2] * image_point[1], image_point[1]\n",
    "            ])\n",
    "            count += 2\n",
    "\n",
    "\n",
    "#         print(A)\n",
    "#         return A\n",
    "        S, V, d = np.linalg.svd(A)\n",
    "        #         print(d)\n",
    "        P = d[-1, :] / d[-1, -1]\n",
    "        P = np.reshape(P, (3, 4))\n",
    "        if change:\n",
    "            self.P = P\n",
    "        return P\n",
    "\n",
    "    def get_KRC(self, change=True):\n",
    "        KR = self.P[np.ix_([0, 1, 2], [0, 1, 2])]\n",
    "        #         print(\"KR = \", KR)\n",
    "        KRC = self.P[np.ix_([0, 1, 2], [3])]\n",
    "        temp = np.dot(KR, KR.T)\n",
    "        temp = temp / temp[2][2]\n",
    "        #         print(\"TEMP = \", temp)\n",
    "        u0 = temp[2][0]\n",
    "        v0 = temp[2][1]\n",
    "        beta = np.sqrt(temp[1][1] - v0 * v0)\n",
    "        gamma = (temp[1][0] - u0 * v0) / beta\n",
    "        alpha = np.sqrt(temp[0][0] - gamma**2 - u0**2)\n",
    "        self.K = np.array([[alpha, gamma, u0], [0, beta, v0], [0, 0, 1]])\n",
    "        inverse = np.linalg.inv(self.K)\n",
    "        self.R = np.dot(inverse, KR)\n",
    "        self.t = np.dot(inverse, KRC)\n",
    "        return self.K, self.R, self.t\n",
    "\n",
    "    def get_image_coordinates(self, real_world_coordinates):\n",
    "        image_coordinates = []\n",
    "        #         print(real_world_coordinates)\n",
    "        for world_point in real_world_coordinates:\n",
    "            world_point = np.array(world_point)\n",
    "            #             print(world_point)\n",
    "            #             world_point.append(1)\n",
    "            #             print(world_point)\n",
    "            world_point = np.append(world_point, 1)\n",
    "            #             print(world_point_)?\n",
    "            res = np.dot(self.P, world_point.T)\n",
    "            image_coordinates.append(res[:2] / res[2])\n",
    "        return image_coordinates\n",
    "\n",
    "    def error(self, X, Y):\n",
    "        return np.mean(np.sqrt([(x - y)**2 for x, y in zip(X, Y)]))\n",
    "\n",
    "    def RANSAC(self,\n",
    "               real_world_coordinates,\n",
    "               image_coordinates,\n",
    "               iterations,\n",
    "               threshold=200,\n",
    "               d=1):\n",
    "        iter = 0\n",
    "        best_fit = None\n",
    "        best_error = 1e+30\n",
    "        while iter < iterations:\n",
    "            index = random.sample([i for i in range(len(image_coordinates))],\n",
    "                                  6)\n",
    "            model_real_world_coordinates = [\n",
    "                real_world_coordinates[i] for i in index\n",
    "            ]\n",
    "            model_image_coordinates = [image_coordinates[i] for i in index]\n",
    "            P = self.get_camera_parameters(model_real_world_coordinates,\n",
    "                                           model_image_coordinates)\n",
    "            no_of_inliners = 0\n",
    "            error = 0.0\n",
    "            check_real_world_coordinates = [\n",
    "                real_world_coordinates[i]\n",
    "                for i in range(len(real_world_coordinates)) if i not in index\n",
    "            ]\n",
    "            check_image_coordinates = [\n",
    "                image_coordinates[i] for i in range(len(image_coordinates))\n",
    "                if i not in index\n",
    "            ]\n",
    "            predicted_image_coordinates = self.get_image_coordinates(\n",
    "                check_real_world_coordinates)\n",
    "            points_with_allowed_error = [\n",
    "                self.error(x, y) for x, y in zip(check_image_coordinates,\n",
    "                                                 predicted_image_coordinates)\n",
    "            ]\n",
    "            #             print(\"fhdskfhadgfdafadslf\", points_with_allowed_error)\n",
    "            index = []\n",
    "            for i in range(len(points_with_allowed_error)):\n",
    "                if points_with_allowed_error[i] < threshold:\n",
    "                    index.append(i)\n",
    "            points_with_allowed_error = [\n",
    "                i for i in points_with_allowed_error if i < threshold\n",
    "            ]\n",
    "            #             print(\n",
    "            #                 \"Hey there delilah whats it like in new york city I am thousand\",\n",
    "            #                 points_with_allowed_error)\n",
    "            if len(points_with_allowed_error) > d:\n",
    "                model_real_world_coordinates = [\n",
    "                    real_world_coordinates[i] for i in index\n",
    "                ]\n",
    "                model_image_coordinates = [image_coordinates[i] for i in index]\n",
    "                P = self.get_camera_parameters(model_real_world_coordinates,\n",
    "                                               model_image_coordinates)\n",
    "                points_with_allowed_error = [\n",
    "                    self.error(x, y) for x, y in zip(\n",
    "                        check_image_coordinates, predicted_image_coordinates)\n",
    "                ]\n",
    "                cur_error = np.mean(points_with_allowed_error)\n",
    "                if cur_error < best_error:\n",
    "                    best_fit = P\n",
    "                    best_error = cur_error\n",
    "            iter += 1\n",
    "        self.P = best_fit\n",
    "        return self.get_KRC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (DLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.113Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "real_world_coordinates = [[0, 0, 0], [0, 12.3, 0],\n",
    "                          [14.5, 12.3, 0], [14.5, 0, 0], [0, 0, 14.5],\n",
    "                          [0, 12.3,\n",
    "                           14.5]]  #, [14.5,12.3,14.5]]#, [14.5,0,14.5]]\n",
    "image_coordinates = [[1302, 1147], [1110, 976], [1411, 863], [1618, 1012],\n",
    "                     [1324, 812], [1127, 658]]  #,[1433,564]]#,[1645,704]]\n",
    "image = [[120.855, 285.603], [904.145, 329.632], [3242.98, 462.119],\n",
    "         [4070.4, 506.248], [4919.89, 561.41], [198.081, 1046.83],\n",
    "         [926.21, 1101.99], [1676.4, 1157.15], [2448.66, 1212.31],\n",
    "         [3220.92, 1267.47], [4026.27, 1333.67], [4875.76, 1388.83],\n",
    "         [661.435, 2105.93], [1433.69, 2172.12], [2216.98, 2238.31],\n",
    "         [3033.37, 2315.54], [3860.79, 2381.73], [4721.31, 2458.96],\n",
    "         [330.468, 2403.8], [1146.85, 2469.99], [3717.37, 2712.7],\n",
    "         [4655.11, 2800.96], [826.919, 2823.02], [2614.15, 2999.54],\n",
    "         [3562.92, 3087.8], [4544.79, 3165.02], [462.855, 3231.22],\n",
    "         [1400.6, 3319.47], [2371.44, 3407.02], [3375.37, 3507.31]]\n",
    "obj = [[6, 2, 0], [5, 2, 0], [2, 2, 0], [1, 2, 0], [0, 2, 0], [6, 1, 0],\n",
    "       [5, 1, 0], [4, 1, 0], [3, 1, 0], [2, 1, 0], [1, 1, 0], [0, 1, 0],\n",
    "       [5, 0, 1], [4, 0, 1], [3, 0, 1], [2, 0, 1], [1, 0, 1], [0, 0, 1],\n",
    "       [5, 0, 2], [4, 0, 2], [1, 0, 2], [0, 0, 2], [4, 0, 3], [2, 0, 3],\n",
    "       [1, 0, 3], [0, 0, 3], [4, 0, 4], [3, 0, 4], [2, 0, 4], [1, 0, 4]]\n",
    "obj = np.array(obj) * 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.116Z"
    }
   },
   "outputs": [],
   "source": [
    "camera = Camera()\n",
    "A = camera.get_camera_parameters(obj[:-3], image[:-3])\n",
    "camera.get_KRC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.118Z"
    }
   },
   "outputs": [],
   "source": [
    "display(camera.get_image_coordinates(obj[-3:]), image[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (RANSAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.135Z"
    }
   },
   "outputs": [],
   "source": [
    "camera.RANSAC(obj, image, iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given images of checker board. The checkerboard has inner point of shape **8X6**. I've used findChessboardCorners to find corners that are inside. \n",
    "Then I've used cv.cameraCalibrate function It resturns the distortion matrix.\n",
    "Using this distortion matrix and camera matrix we can find new camera matrix.\n",
    "Which in then used to undistort image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.179Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "objp = np.zeros((6 * 8, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2)\n",
    "objpoints = []\n",
    "imgpoints = [] \n",
    "img_path = glob('*.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.181Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path.remove(\"IMG_5455.JPG\")\n",
    "for path in img_path:\n",
    "    img = cv.imread(path)\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv.findChessboardCorners(gray, (8, 6), None)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners)\n",
    "        cv.waitKey(2000)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.185Z"
    }
   },
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(\n",
    "    objpoints, imgpoints, (gray.shape[1], gray.shape[0]), None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.187Z"
    }
   },
   "outputs": [],
   "source": [
    "im___ = cv.imread(\"IMG_5457.JPG\")\n",
    "plt.imshow(im___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.190Z"
    }
   },
   "outputs": [],
   "source": [
    "h, w = im___.shape[:2]\n",
    "new_camera_mtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1,\n",
    "                                                   (w, h))\n",
    "# print(new_camera_mtx, mtx)\n",
    "dst = cv.undistort(im___, mtx, dist, None, new_camera_mtx)\n",
    "x, y, w, h = roi\n",
    "dst = cv.resize(dst, (h, w))\n",
    "dst = dst[y:y + h, x:x + w]\n",
    "# print(dst)\n",
    "plt.imshow(dst)\n",
    "cv.imwrite(\"undistorted.jpg\", dst)\n",
    "cv.waitKey(2000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.192Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\"ret\", ret)\n",
    "display(\"mtx\", mtx)\n",
    "display(\"dist\", dist)\n",
    "display(\"rvecs\", rvecs)\n",
    "display(\"tvecs\", tvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have drawn image of 3-D cube. I have taken a unit cube with one point at origin. Then used the calculated camera matrix form DLT to find image coordinates. \n",
    "These points are then connected to form cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.235Z"
    }
   },
   "outputs": [],
   "source": [
    "measurement = cv.imread(\"measurements.jpg\")\n",
    "wireframe_iamge = cv.imread(\"IMG_5455.JPG\")\n",
    "wireframe_iamge = cv.resize(wireframe_iamge, (548, 365))\n",
    "print(measurement.shape, wireframe_iamge.shape)\n",
    "i = 0\n",
    "predicted_points = camera.get_image_coordinates(obj)\n",
    "_3d_corners = np.float32([[0, 0, 0], [1, 0, 0], [1, 0, 1], [0, 0, 1],\n",
    "                          [0, 1, 0], [1, 1, 0], [1, 1, 1], [0, 1, 1]]) * 72\n",
    "cube_corners_2d = np.array(camera.get_image_coordinates(_3d_corners)) / 10\n",
    "cube_corners_2d = np.array(cube_corners_2d, np.int32)\n",
    "red = (0, 0, 255)\n",
    "line_width = 2\n",
    "\n",
    "#first draw the base in red\n",
    "for i in range(4):\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[i]),\n",
    "            tuple(cube_corners_2d[(i + 1) % 4]), red, line_width)\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[i]),\n",
    "            tuple(cube_corners_2d[i + 4]), red, line_width)\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[4 + i]),\n",
    "            tuple(cube_corners_2d[(i + 1) % 4 + 4]), red, line_width)\n",
    "plt.imshow(wireframe_iamge)\n",
    "cv.waitKey(5000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have drawn image of 3-D cube. I have taken a cube with one point at origin. Then used the calculated camera matrix form DLT to find image coordinates. These points are then connected to form cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.277Z"
    }
   },
   "outputs": [],
   "source": [
    "img_index = 0\n",
    "wireframe_iamge = cv.imread(img_path[img_index])\n",
    "wireframe_iamge = cv.resize(wireframe_iamge, (548, 365))\n",
    "#     _3d_corners = np.float32([[0,0,0], [1,0,0], [1,0,1], [0,0,1],\n",
    "#                                    [0,1,0],[1,1,0],[1,1,1],[0,1,1]])*2\n",
    "_3d_corners = np.float32([[0, 0, 0], [0, 3, 0], [3, 3, 0], [3, 0, 0],\n",
    "                          [0, 0, -3], [0, 3, -3], [3, 3, -3], [3, 0, -3]])\n",
    "cube_corners_2d, _ = cv.projectPoints(_3d_corners, rvecs[img_index],\n",
    "                                      tvecs[img_index], mtx, dist)\n",
    "# print(cube_corners_2d)\n",
    "cube_corners_2d = np.array(cube_corners_2d, np.int32) / 10\n",
    "cube_corners_2d = np.array(cube_corners_2d, np.int32)\n",
    "red = (0, 0, 255)\n",
    "line_width = 2\n",
    "cv.circle(wireframe_iamge, tuple(cube_corners_2d[0][0]), 10, (255, 0, 0),\n",
    "          10)\n",
    "for i in range(4):\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[i][0]),\n",
    "            tuple(cube_corners_2d[(i + 1) % 4][0]), red, line_width)\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[i][0]),\n",
    "            tuple(cube_corners_2d[i + 4][0]), red, line_width)\n",
    "    cv.line(wireframe_iamge, tuple(cube_corners_2d[4 + i][0]),\n",
    "            tuple(cube_corners_2d[(i + 1) % 4 + 4][0]), red, line_width)\n",
    "plt.imshow( wireframe_iamge)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.300Z"
    }
   },
   "outputs": [],
   "source": [
    "print(camera.get_image_coordinates([[0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "Results observed from DLT and RANSAC are satisfactory. Because I've used 33 points to calibrate camera in DLT. The camera used for images are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-03T15:27:02.323Z"
    }
   },
   "outputs": [],
   "source": [
    "img=cv.imread('DLT.jpg')\n",
    "print(img.shape)\n",
    "img = cv.resize(img, (409, 230))\n",
    "cv.imshow('img', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
