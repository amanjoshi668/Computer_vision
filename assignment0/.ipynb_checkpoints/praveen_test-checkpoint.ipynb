{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1a - Converting Video to Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From video to images\n",
    "def convertVidToFrames(pathIn, pathOut):\n",
    "    vidcap = cv2.VideoCapture(os.path.abspath(pathIn),filename)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "      cv2.imwrite(os.path.join(os.path.abspath(pathOut),\"frame%d.jpg\" % count), image)     # save frame as JPEG file      \n",
    "      success,image = vidcap.read()\n",
    "    #   print('Read a new frame: ', success)\n",
    "      count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the video path and output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vidpath = \"./a.mp4\"\n",
    "pathout = \"./imgs\"\n",
    "convertVidToFrames(Vidpath, pathout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1b - Convert Frames to Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    " \n",
    "def convert_frames_to_video(pathIn,pathOut,fps):\n",
    "    pathIn = os.path.abspath(pathIn)\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    " \n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: int(x[5:-4]))\n",
    " \n",
    "    for i in range(len(files)):\n",
    "        filename=os.path.join(pathIn,files[i])\n",
    "        #reading each files\n",
    "        img = cv2.imread(filename)\n",
    "#         cv2.imshow('image',img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        height, width, layers = img.shape\n",
    "#         print(img.shape)\n",
    "        size = (width,height)\n",
    "#         print(filename)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    "#     print(pathOut)\n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        out.write(frame_array[i])\n",
    "#     print(\"hello\")\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input the frames location and output file name (saves the video in the current working dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/praveen/Desktop/iiith-assignments/CV/Assignment0/out.mp4\n",
      "/home/praveen/Desktop/iiith-assignments/CV/Assignment0/out.mp4\n",
      "132\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "pathIn= './imgs'\n",
    "pathOut = os.path.join(os.getcwd(),'out.mp4')\n",
    "fps = 25.0\n",
    "convert_frames_to_video(pathIn, pathOut, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Clicking images from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"clickImage\")\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    cv2.imshow(\"clickImage\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    press_key = cv2.waitKey(1)\n",
    "\n",
    "    if press_key == 27:\n",
    "        break\n",
    "    elif press_key == 32:\n",
    "        img = \"Pic_{0}.JPEG\".format(img_counter)\n",
    "        cv2.imwrite(img, frame)\n",
    "        print(\"{0} written!\".format(img))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Chroma Keying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: Merge two videos, one with a foreground object and another with background(Green Screen)\n",
    "### Solution: \n",
    "1. Check the pixels where green color is dominant and change the intensitiy (alpha) to zero, rest where the actual foreground object is present, change the intensity to 255(MAX)\n",
    "2. Merge the above filtered object onto the background image and set the relevant pixels(pixels where intensity of foreground(alpha) = 255 to those of the object background\n",
    "3. Follow the above process for each set of frames from foreground and background and write them to a file\n",
    "\n",
    "### Challenges:\n",
    "1. While checking for pixels where green is dominant, taking difference on pixel values casues an issue as the datatype is uint. Dividing it by 1 changes it to float\n",
    "2. cv2.imread() - reads the image in RGB format, had to convert it to RGBA format\n",
    "3. Since the at the object boundaries, the pixel density dilutes, had to play around with the threshold above which the pixel would be considered as that of the foreground object\n",
    "4. While merging videos, since the length of both the videos might not be same, had to loop the background video\n",
    "5. While saving videos, the \n",
    "\n",
    "### Learnings:\n",
    "1. Learn how to work with images and videos with openCV\n",
    "2. Learn about what an image is (formats, pixels, etc)\n",
    "3. Learn about Chroma Keying, and how to do it using openCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2.cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-065447ec7545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2.cv'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.misc import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shapes read from iread\n",
    "foreground = imread('girl.jpg', mode ='RGBA')\n",
    "background = imread('back.jpg', mode ='RGBA')\n",
    "print(foreground.shape, background.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the images\n",
    "plt.imshow(foreground)\n",
    "plt.imshow(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filering the green color\n",
    "def filterBackGround(image):\n",
    "    #converting from uint to float, to handle negative values\n",
    "    red_layer = image[:,:,0]/1\n",
    "    green_layer = image[:,:,1]/1\n",
    "    blue_layer = image[:,:,2]/1\n",
    "    \n",
    "    red_diff_green = red_layer - green_layer + 50\n",
    "    blue_diff_green = blue_layer - green_layer + 50\n",
    "    \n",
    "    red_diff_green[red_diff_green < 0] = 0\n",
    "    blue_diff_green[blue_diff_green < 0] = 0\n",
    "    \n",
    "    alpha = red_diff_green + blue_diff_green\n",
    "    alpha[alpha > 30] = 255\n",
    "    alpha[alpha <= 30] = 0\n",
    "    \n",
    "    image[:,:,3] = alpha\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = filterBackGround(foreground)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(foreground, background, x_offset=0, y_offset=0):\n",
    "    (y_size, x_size, _) = foreground.shape\n",
    "    crop_start_x = x_offset\n",
    "    crop_end_x = crop_start_x + x_size\n",
    "    crop_start_y = y_offset\n",
    "    crop_end_y = crop_start_y + y_size\n",
    "    bg_cropped = background[crop_start_y:crop_end_y,\n",
    "                           crop_start_x:crop_end_x,\n",
    "                           :]\n",
    "    foreground_pixels = (foreground[:,:,-1] > 10)\n",
    "#     print(bg_cropped.shape, foreground.shape, foreground_pixels.shape)\n",
    "    bg_cropped[foreground_pixels] = foreground[foreground_pixels]\n",
    "    background[crop_start_y:crop_end_y,\n",
    "                crop_start_x:crop_end_x,\n",
    "                :] = bg_cropped\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_img = merge(img, background,30)\n",
    "plt.imshow(merged_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2rgba(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2RGBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import isfile, join\n",
    " \n",
    "def mergeVideos(foreground_path, background_path, pathOut):\n",
    "    foreground_path = os.path.abspath(foreground_path)\n",
    "    background_path = os.path.abspath(background_path)\n",
    "    print(foreground_path, background_path)\n",
    "    pathOut = os.path.abspath(pathOut)\n",
    "    print(pathOut)\n",
    "    #storing output frames\n",
    "    frame_array = []\n",
    "    front = cv2.VideoCapture(foreground_path)\n",
    "    back = cv2.VideoCapture(background_path)\n",
    "    front_ret = True\n",
    "    count = 0;\n",
    "    while(front.isOpened()):\n",
    "        front_ret, front_frame = front.read()\n",
    "        if(not front_ret):\n",
    "            break;\n",
    "        back_ret, back_frame = back.read()\n",
    "        count += 1\n",
    "        if count == back.get(cv2.CV_CAP_PROP_FRAME_COUNT):\n",
    "            count = 0 #Or whatever as long as it is the same as next line\n",
    "            back.set(cv2.CV_CAP_PROP_POS_FRAMES, 0)\n",
    "        front_frame = rgb2rgba(front_frame)\n",
    "        back_frame = rgb2rgba(back_frame)\n",
    "        (height, width, _) = back_frame.shape\n",
    "        size = (width,height)\n",
    "        front_filtered = filterBackGround(front_frame)\n",
    "        merged_img = merge(front_filtered, back_frame)\n",
    "        frame_array.append(merged_img)\n",
    "        cv2.imshow('frame',merged_img)\n",
    "        if ((cv2.waitKey(1) & 0xFF == ord('q')) or (not front_ret)):\n",
    "            break\n",
    "    out = cv2.VideoWriter(pathOut,-1, fps, size)\n",
    "    for i in range(len(frame_array)):\n",
    "        out.write(frame_array[i])\n",
    "    front.release()\n",
    "    back.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3) (720, 1280, 3)\n",
      "(720, 1280, 4) (720, 1280, 4)\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "front = cv2.VideoCapture('lion.mp4')\n",
    "back = cv2.VideoCapture('city.mp4')\n",
    "#checking resolution\n",
    "front_frame = front.read()[1]\n",
    "back_frame = back.read()[1]\n",
    "print(front_frame.shape, back_frame.shape)\n",
    "front_frame = rgb2rgba(front_frame)\n",
    "back_frame = rgb2rgba(back_frame)\n",
    "cv2.imshow('frame',back_frame)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imshow('frame',merged_img)\n",
    "print(front_frame.shape, back_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/praveen/Desktop/iiith-assignments/CV/Assignment0/lion.mp4 /home/praveen/Desktop/iiith-assignments/CV/Assignment0/city.mp4\n",
      "/home/praveen/Desktop/iiith-assignments/CV/Assignment0/merged_vid.mp4\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'CV_CAP_PROP_FRAME_COUNT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ae96f751f6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbg_video_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./city.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./merged_vid.mp4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmergeVideos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfg_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-c81150e68cd5>\u001b[0m in \u001b[0;36mmergeVideos\u001b[0;34m(foreground_path, background_path, pathOut)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mback_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_CAP_PROP_FRAME_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m#Or whatever as long as it is the same as next line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCV_CAP_PROP_POS_FRAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'CV_CAP_PROP_FRAME_COUNT'"
     ]
    }
   ],
   "source": [
    "fg_video_path = \"./lion.mp4\"\n",
    "bg_video_path = \"./city.mp4\"\n",
    "out_path = \"./merged_vid.mp4\"\n",
    "mergeVideos(fg_video_path, bg_video_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
