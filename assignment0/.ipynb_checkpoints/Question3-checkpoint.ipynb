{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 0\n",
    "- Aman Joshi (2018201097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (videoâ†” images)\n",
    "### Convert video to images\n",
    "I've used cv2 for converting video to images. The function is taking video path and desetination folder as arguments.\n",
    "* Read the video frame by frame using cv.VideoCapture()\n",
    "* Then for each succesfull read of the frame write it to the destination folder using cv.imwrite.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_video_to_image(video_name, folder_path):\n",
    "    cap = cv.VideoCapture(video_name)\n",
    "    cnt = 1\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            cv.imshow('frame', frame)\n",
    "            key = cv.waitKey(1)\n",
    "            if (key == ord('q')):\n",
    "                break\n",
    "            cv.imwrite(os.path.join(folder_path, 'frame'+str(cnt)+'.jpg'), frame)\n",
    "            cnt += 1\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    except:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_video_to_image('cute.mp4', 'result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert video to images\n",
    "I've used cv2 for converting iamges to video. The function is taking image folder and desetination video as arguments.\n",
    "* Read the all file name using os.listdir also sort them (if theya re part of some video and been stored in some ordered fashioned).\n",
    "* Create a Video Writer object for writing video.\n",
    "* Pass f.p.s. and size of frame to it.\n",
    "* Read each image using cv.imread() and write it to video writer object.\n",
    "* Release video object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images_to_video(image_folder, video_path):\n",
    "    only_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv.VideoWriter(video_path,fourcc, 20, (1280,720))\n",
    "    try:\n",
    "        for f in only_files:\n",
    "            frame = cv.imread(os.path.join(image_folder,f))\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "        cv.destroyAllWindows()\n",
    "    except:\n",
    "        out.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_images_to_video('result', 'result.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (Capturing Images)\n",
    "I've used cv2 for capturing stream from webcam of laptop. The function is taking destination folder where screen shots will get saved (By default screen).\n",
    "* Read the stream frame by frame.\n",
    "* Show image for 1ms.\n",
    "* Read the key pressed during the display time i.e. 1ms\n",
    "* Whenever 'c' is pressed it will save the current frame at the specified destination using cv.imwrite()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera(screen_folder = \"screen\"):\n",
    "    cap = cv.VideoCapture(0)\n",
    "    cnt = 0\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv.flip(frame, 1)\n",
    "            cv.imshow('frame', frame[::])\n",
    "            key = cv.waitKey(1)\n",
    "            if (key == ord('c')):\n",
    "                cnt = cnt+1\n",
    "                cv.imwrite(os.path.join(screen_folder , str(cnt) + \".jpg\"), frame)\n",
    "            elif (key == ord('q')):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "    except:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press \"q\" for exiting\n",
      "Press \"c\" for taking snapshot\n"
     ]
    }
   ],
   "source": [
    "print('Press \"q\" for exiting')\n",
    "print('Press \"c\" for taking snapshot')\n",
    "camera(\"screen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (Chroma Keying)\n",
    "Merge Two Videos, One with a foreground object with green background, While the other video is of a Background.\n",
    "\n",
    "* Read both videos frame by frame\n",
    "* Mark the green dominant regions of the frame and store them in alpha. \n",
    "* Alpha = 0 means that the region was green dominant (to be removed) while alpha = 1 means the region is to be kept.\n",
    "* Replace all the non green dominant region from the background image with the pixel values from the foreground image.\n",
    "* Save the frames to video with the above mentioned process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_green(img):\n",
    "    r = img[:, :, 0]/1\n",
    "    g = img[:, :, 1]/1 \n",
    "    b = img[:, :, 2]/1\n",
    "    red_vs_green = (r - g) + 20\n",
    "    blue_vs_green = (b - g) + 20\n",
    "    red_vs_green[red_vs_green < 0] = 0\n",
    "    blue_vs_green[blue_vs_green < 0] = 0\n",
    "    \n",
    "    alpha = (red_vs_green + blue_vs_green) \n",
    "    alpha[alpha > 50] = 255\n",
    "    alpha = alpha/255;\n",
    "    \n",
    "    return img, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(bg, img, alpha):\n",
    "    pixel_preserve = (alpha > 0)\n",
    "    bg[pixel_preserve] = img[pixel_preserve]\n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_videos(foreground, background):\n",
    "    cap1 = cv.VideoCapture(foreground)\n",
    "    cap2 = cv.VideoCapture(background)\n",
    "\n",
    "    out = cv.VideoWriter('result_q3.mp4',-1, 20, (1280,720))\n",
    "    cnt = 0\n",
    "    try:\n",
    "        while(cap1.isOpened()):\n",
    "            if(not cap2.isOpened()):\n",
    "                cap2 = cv.VideoCapture(background)\n",
    "            ret, fg = cap1.read()\n",
    "            ret, bg = cap2.read()   \n",
    "            if cnt == 240:\n",
    "                cv.imwrite('fg_image.jpg', fg)\n",
    "                cv.imwrite('bg_image.jpg', bg)\n",
    "            h,w = fg.shape[:2]\n",
    "            bg = cv.resize(bg, (w,h))\n",
    "            \n",
    "            fg, alpha = remove_green(fg)\n",
    "            bg = blend(bg, fg, alpha)\n",
    "            \n",
    "            if cnt == 240:\n",
    "                cv.imwrite('merged_image.jpg', bg)\n",
    "            cnt += 1\n",
    "            cv.imshow('merged', bg)\n",
    "            key = cv.waitKey(1)\n",
    "            if (key == ord('q')):\n",
    "                    break\n",
    "\n",
    "            out.write(bg)\n",
    "\n",
    "        out.release()\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        cv.destroyAllWindows()\n",
    "    except:\n",
    "        cap1.release()\n",
    "        cap2.release()\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_two_videos('foreground.mp4', 'background.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnings\n",
    "* Learn how to open, save, show images using opencv.\n",
    "* Process videos frame by frame and treat each frame as images.\n",
    "* Learn Chroma Keying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challanges\n",
    "* Combining images to make vide. Unordered reading using os.listdir().\n",
    "* By doing operations on the color matrix lead to overflow. Thus changing its data type by doing some operations, like dividing by 1.\n",
    "* Hard to figure out the threshold, allowing upto which limit pixels from the foreground should be permitted.\n",
    "* Installing opencv on python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
